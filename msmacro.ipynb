{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e979c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neulab/codebert-cpp\n",
    "#microsoft/graphcodebert-base\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acee7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10be0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.code1 = data['code1'].to_numpy()\n",
    "        self.code2 = data['code2'].to_numpy()\n",
    "        if 'similar' in data.columns:\n",
    "            self.labels = data['similar'].to_numpy()\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.code1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code1 = self.code1[idx]\n",
    "        code2 = self.code2[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            code1,\n",
    "            code2,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding='max_length'\n",
    "        )\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return {'input_ids': encoding['input_ids'][0],\n",
    "                    'attention_mask': encoding['attention_mask'][0],\n",
    "                    'token_type_ids' : encoding['token_type_ids'][0],\n",
    "                    'labels': torch.tensor(label, dtype=torch.long)}\n",
    "        else:\n",
    "            return {'input_ids': encoding['input_ids'][0],\n",
    "                    'attention_mask': encoding['attention_mask'][0],\n",
    "                    'token_type_ids' : encoding['token_type_ids'][0],\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcf0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server4/anaconda3/envs/jy/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"neulab/codebert-cpp\"\n",
    "model_name = 'OpenMatch/cocodr-base-msmarco'\n",
    "train_data = pd.read_csv('./sample_train.csv')\n",
    "train_data = pd.concat([train_data,pd.DataFrame({'code1_path':train_data['code2_path'],\n",
    "                                     'code2_path':train_data['code1_path'],\n",
    "                                     'code1':train_data['code2'],\n",
    "                                     'code2':train_data['code1'],\n",
    "                                     'similar':train_data['similar']})])\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "train_dataset = NewsDataset(train_data, tokenizer, max_len=512)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ccf8e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72bfa30b7874377a1d3c6c91bb60678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch : 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1959.6602111458778\n",
      "acc = 0.6460750102996826\n",
      "count = 18983\n",
      "\n",
      "epoch : 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1409.9522180370986\n",
      "acc = 0.7660250067710876\n",
      "count = 19203\n",
      "\n",
      "epoch : 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1218.9238634612411\n",
      "acc = 0.8017249703407288\n",
      "count = 19675\n",
      "\n",
      "epoch : 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 1056.081231017597\n",
      "acc = 0.8299749493598938\n",
      "count = 19991\n",
      "\n",
      "epoch : 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 919.0171136641875\n",
      "acc = 0.8568750023841858\n",
      "count = 20161\n",
      "\n",
      "epoch : 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 785.224192088237\n",
      "acc = 0.8825249671936035\n",
      "count = 20191\n",
      "\n",
      "epoch : 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 648.910987239331\n",
      "acc = 0.9069749712944031\n",
      "count = 20143\n",
      "\n",
      "epoch : 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 511.5259664467012\n",
      "acc = 0.9301249980926514\n",
      "count = 20103\n",
      "\n",
      "epoch : 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 402.00858118436736\n",
      "acc = 0.9475749731063843\n",
      "count = 20027\n",
      "\n",
      "epoch : 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 311.4317935223371\n",
      "acc = 0.9607499837875366\n",
      "count = 20022\n",
      "\n",
      "epoch : 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss : 243.6657302414369\n",
      "acc = 0.9704749584197998\n",
      "count = 20023\n",
      "\n",
      "epoch : 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7937b30e154c2f9b3a93dccc214b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mepoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader),leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)):\n\u001b[0;32m----> 8\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "    print(f'\\nepoch : {epoch+1}')\n",
    "    for i, batch in tqdm(enumerate(train_loader),leave=False,total=len(train_loader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, axis=1)\n",
    "        acc += torch.sum(labels==preds)\n",
    "        cnt += torch.sum(preds)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    model.save_pretrained(f\"model_msmacro/cpp-{epoch}\", from_pt=True)\n",
    "    print(f'train_loss : {train_loss}\\nacc = {acc / len(train_data)}\\ncount = {cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc320ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'OpenMatch/cocodr-base-msmarco'\n",
    "\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "test_dataset = NewsDataset(test_data, tokenizer, max_len=512)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=252, shuffle=False, num_workers=4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c90000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d81ddd51c84c67b921bcfde8ae8c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"model_msmacro/cpp-10\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    for i, batch in tqdm(enumerate(test_loader),total=len(test_loader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, axis=1)\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "submission = pd.DataFrame({'pair_id': test_data['pair_id'], 'similar': test_preds})\n",
    "submission.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c208fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90364"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.read_csv('submission.csv')['similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef373d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
